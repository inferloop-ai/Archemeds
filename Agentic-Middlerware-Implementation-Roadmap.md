# Agentic Middleware - Implementation Roadmap

## üéØ **Implementation Strategy**

This roadmap follows a **bottom-up, incremental approach** that allows you to build, test, and validate each component before moving to the next level of complexity.

## üìÖ **Phase-by-Phase Implementation**

---

## **Phase 1: Foundation (Week 1)**
*Goal: Basic project structure and core models*

### **Step 1.1: Project Setup (Day 1)**
```bash
# Create directory structure
python setup_middleware_script.py
cd ai-code-editor/backend

# Setup virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Create basic requirements
pip install fastapi uvicorn pydantic redis python-dotenv
pip freeze > requirements/base.txt
```

### **Step 1.2: Core Data Models (Day 1-2)**
**Priority: CRITICAL** ‚≠ê‚≠ê‚≠ê

Create foundational models first:

```python
# backend/models/agent_models.py
from enum import Enum
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
from datetime import datetime

class AgentType(str, Enum):
    CODE = "code"
    INFRASTRUCTURE = "infrastructure"
    TESTING = "testing"

class TaskStatus(str, Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"

class IntentType(str, Enum):
    CODE_GENERATION = "code_generation"
    INFRASTRUCTURE_SETUP = "infrastructure_setup"
    TESTING = "testing"

class ExecutionContext(BaseModel):
    session_id: str
    user_id: str
    project_id: str
    workspace_path: str
    metadata: Dict[str, Any] = {}

class TaskRequest(BaseModel):
    id: str
    intent: IntentType
    description: str
    context: ExecutionContext
    parameters: Dict[str, Any] = {}

class TaskResult(BaseModel):
    task_id: str
    agent_type: AgentType
    status: TaskStatus
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
```

### **Step 1.3: Basic FastAPI App (Day 2)**
**Priority: CRITICAL** ‚≠ê‚≠ê‚≠ê

```python
# backend/app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="AI Code Editor", version="0.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.get("/")
async def root():
    return {"message": "AI Code Editor API"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
```

**Test:** Run the server and verify `/health` endpoint works.

---

## **Phase 2: Base Agent System (Week 1-2)**
*Goal: Simple agent framework that can execute basic tasks*

### **Step 2.1: Base Agent Classes (Day 3)**
**Priority: CRITICAL** ‚≠ê‚≠ê‚≠ê

```python
# backend/agents/base/agent.py
from abc import ABC, abstractmethod
from typing import List
from ...models.agent_models import TaskRequest, TaskResult, AgentCapability

class BaseAgent(ABC):
    def __init__(self, agent_type: AgentType):
        self.agent_type = agent_type
        self.capabilities = []
    
    @abstractmethod
    async def execute(self, task: TaskRequest) -> TaskResult:
        pass
    
    @abstractmethod
    async def can_handle(self, task: TaskRequest) -> bool:
        pass
    
    def get_capabilities(self) -> List[AgentCapability]:
        return self.capabilities
```

### **Step 2.2: Mock LLM Client (Day 3)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/core/llm/mock_client.py
class MockLLMClient:
    async def chat_completion(self, messages: List[Dict[str, str]]):
        # Simple mock responses for testing
        user_message = messages[-1]["content"].lower()
        
        if "fastapi" in user_message:
            return MockResponse(json.dumps({
                "code": "from fastapi import FastAPI\n\napp = FastAPI()",
                "explanation": "Basic FastAPI app"
            }))
        
        return MockResponse("Mock response")

class MockResponse:
    def __init__(self, content: str):
        self.content = content
```

### **Step 2.3: Simple Code Agent (Day 4)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/agents/code/code_agent.py
from ..base.agent import BaseAgent
from ...models.agent_models import AgentType, TaskRequest, TaskResult, TaskStatus

class CodeGenerationAgent(BaseAgent):
    def __init__(self, llm_client=None):
        super().__init__(AgentType.CODE)
        self.llm_client = llm_client
    
    async def can_handle(self, task: TaskRequest) -> bool:
        return task.intent == IntentType.CODE_GENERATION
    
    async def execute(self, task: TaskRequest) -> TaskResult:
        try:
            # Simple code generation logic
            response = await self.llm_client.chat_completion([
                {"role": "user", "content": task.description}
            ])
            
            return TaskResult(
                task_id=task.id,
                agent_type=self.agent_type,
                status=TaskStatus.COMPLETED,
                result={"code": response.content}
            )
        except Exception as e:
            return TaskResult(
                task_id=task.id,
                agent_type=self.agent_type,
                status=TaskStatus.FAILED,
                error=str(e)
            )
```

**Test:** Create a simple test to verify the agent can execute a task.

---

## **Phase 3: Basic Orchestration (Week 2)**
*Goal: Simple middleware that can route tasks to agents*

### **Step 3.1: Agent Registry (Day 5)**
**Priority: CRITICAL** ‚≠ê‚≠ê‚≠ê

```python
# backend/core/orchestration/agent_registry.py
from typing import Dict, List
from ...models.agent_models import AgentType, TaskRequest

class AgentRegistry:
    def __init__(self):
        self.agents: Dict[AgentType, BaseAgent] = {}
    
    def register_agent(self, agent):
        self.agents[agent.agent_type] = agent
    
    async def find_capable_agents(self, task: TaskRequest) -> List:
        capable_agents = []
        for agent in self.agents.values():
            if await agent.can_handle(task):
                capable_agents.append(agent)
        return capable_agents
```

### **Step 3.2: Simple Intent Classifier (Day 6)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/core/orchestration/intent_classifier.py
from ...models.agent_models import IntentType, ExecutionContext

class IntentClassifier:
    def __init__(self):
        self.keywords = {
            IntentType.CODE_GENERATION: ["create", "generate", "write code", "implement"],
            IntentType.INFRASTRUCTURE_SETUP: ["docker", "deploy", "kubernetes"],
            IntentType.TESTING: ["test", "testing", "unit test"]
        }
    
    async def classify(self, user_input: str, context: ExecutionContext) -> IntentType:
        user_input_lower = user_input.lower()
        
        for intent, keywords in self.keywords.items():
            if any(keyword in user_input_lower for keyword in keywords):
                return intent
        
        return IntentType.CODE_GENERATION  # Default
```

### **Step 3.3: Basic Middleware (Day 7)**
**Priority: CRITICAL** ‚≠ê‚≠ê‚≠ê

```python
# backend/core/orchestration/middleware.py
from .agent_registry import AgentRegistry
from .intent_classifier import IntentClassifier
from ...models.agent_models import ExecutionContext, TaskRequest

class AgenticMiddleware:
    def __init__(self):
        self.agent_registry = AgentRegistry()
        self.intent_classifier = IntentClassifier()
    
    async def initialize(self):
        print("Middleware initialized")
    
    async def process_request(self, user_input: str, context: ExecutionContext):
        # Classify intent
        intent = await self.intent_classifier.classify(user_input, context)
        
        # Create task
        task = TaskRequest(
            id=str(uuid.uuid4()),
            intent=intent,
            description=user_input,
            context=context
        )
        
        # Find and execute with capable agent
        agents = await self.agent_registry.find_capable_agents(task)
        if agents:
            result = await agents[0].execute(task)
            return {"status": result.status.value, "result": result.result}
        
        return {"error": "No capable agents found"}
    
    def register_agent(self, agent):
        self.agent_registry.register_agent(agent)
```

**Test:** End-to-end test with middleware processing a simple code request.

---

## **Phase 4: API Integration (Week 2-3)**
*Goal: REST API that exposes middleware functionality*

### **Step 4.1: Basic API Endpoints (Day 8)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/api/v1/middleware_api.py
from fastapi import APIRouter, HTTPException
from ...core.orchestration.middleware import AgenticMiddleware
from ...models.agent_models import ExecutionContext

router = APIRouter()
middleware = None

class ChatMessage(BaseModel):
    message: str
    session_id: str
    user_id: str = "default"
    project_id: str = "default"
    workspace_path: str = "/tmp"

@router.post("/chat")
async def chat(message: ChatMessage):
    global middleware
    if not middleware:
        raise HTTPException(status_code=503, detail="Middleware not initialized")
    
    context = ExecutionContext(
        session_id=message.session_id,
        user_id=message.user_id,
        project_id=message.project_id,
        workspace_path=message.workspace_path
    )
    
    response = await middleware.process_request(message.message, context)
    return response

@router.get("/agents")
async def list_agents():
    if middleware:
        return {"agents": list(middleware.agent_registry.agents.keys())}
    return {"agents": []}
```

### **Step 4.2: Integrate with Main App (Day 8)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/app/main.py (updated)
from ..api.v1.middleware_api import router as middleware_router
from ..core.orchestration.middleware import AgenticMiddleware
from ..agents.code.code_agent import CodeGenerationAgent
from ..core.llm.mock_client import MockLLMClient

app.include_router(middleware_router, prefix="/api/v1")

middleware = None

@app.on_event("startup")
async def startup_event():
    global middleware
    middleware = AgenticMiddleware()
    await middleware.initialize()
    
    # Register agents
    llm_client = MockLLMClient()
    code_agent = CodeGenerationAgent(llm_client)
    middleware.register_agent(code_agent)
    
    # Make middleware available to API routes
    import backend.api.v1.middleware_api as api_module
    api_module.middleware = middleware
```

**Test:** Call `/api/v1/chat` endpoint with a code generation request.

---

## **Phase 5: Enhanced Agents (Week 3-4)**
*Goal: Multiple specialized agents with better capabilities*

### **Step 5.1: Infrastructure Agent (Day 9-10)**
**Priority: MEDIUM** ‚≠ê

```python
# backend/agents/infrastructure/infra_agent.py
class InfrastructureAgent(BaseAgent):
    # Implementation for Docker, K8s generation
    pass
```

### **Step 5.2: Testing Agent (Day 11-12)**
**Priority: MEDIUM** ‚≠ê

```python
# backend/agents/testing/test_agent.py
class TestingAgent(BaseAgent):
    # Implementation for test generation
    pass
```

### **Step 5.3: Agent Factory (Day 13)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/agents/factory.py
class AgentFactory:
    @staticmethod
    def create_all_agents(llm_client):
        return [
            CodeGenerationAgent(llm_client),
            InfrastructureAgent(llm_client),
            TestingAgent(llm_client)
        ]
```

**Test:** Multiple agents handling different types of requests.

---

## **Phase 6: Advanced Features (Week 4-5)**
*Goal: Task planning, memory, and sophisticated orchestration*

### **Step 6.1: Redis Integration (Day 14)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/core/memory/context_manager.py
import redis
import json

class ContextMemory:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
    
    async def store_context(self, session_id: str, key: str, value: Any):
        self.redis.setex(f"context:{session_id}:{key}", 3600, json.dumps(value))
    
    async def get_context(self, session_id: str, key: str):
        data = self.redis.get(f"context:{session_id}:{key}")
        return json.loads(data) if data else None
```

### **Step 6.2: Task Planning (Day 15-16)**
**Priority: MEDIUM** ‚≠ê

```python
# backend/core/orchestration/task_planner.py
class TaskPlanner:
    async def create_plan(self, task: TaskRequest):
        # Break complex tasks into subtasks
        pass
```

### **Step 6.3: Real LLM Integration (Day 17)**
**Priority: HIGH** ‚≠ê‚≠ê

```python
# backend/core/llm/openai_provider.py
import openai

class OpenAIProvider:
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
    
    async def chat_completion(self, messages):
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages
        )
        return response.choices[0].message
```

**Test:** Real LLM generating actual code and infrastructure.

---

## **Phase 7: Real-time Communication (Week 5-6)**
*Goal: WebSocket support and live updates*

### **Step 7.1: WebSocket Integration (Day 18-19)**
**Priority: MEDIUM** ‚≠ê

```python
# backend/api/v1/websocket.py
from fastapi import WebSocket

@router.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    await websocket.accept()
    # Handle real-time communication
```

### **Step 7.2: Background Tasks (Day 20)**
**Priority: MEDIUM** ‚≠ê

```python
# backend/core/orchestration/task_processor.py
class TaskProcessor:
    async def process_async(self, task: TaskRequest):
        # Background task processing
        pass
```

---

## **Phase 8: Frontend Integration (Week 6-7)**
*Goal: Connect React frontend to the middleware*

### **Step 8.1: Frontend API Client (Day 21-22)**
**Priority: HIGH** ‚≠ê‚≠ê

```typescript
// frontend/src/services/api/middleware.ts
class MiddlewareAPI {
  async sendMessage(message: string, sessionId: string) {
    // API integration
  }
}
```

### **Step 8.2: Chat Interface (Day 23-24)**
**Priority: HIGH** ‚≠ê‚≠ê

```tsx
// frontend/src/components/chat/ChatInterface.tsx
// React component for chat interaction
```

---

## **Phase 9: Production Features (Week 7-8)**
*Goal: Security, monitoring, deployment*

### **Step 9.1: Authentication (Day 25)**
**Priority: HIGH** ‚≠ê‚≠ê

### **Step 9.2: Rate Limiting (Day 26)**
**Priority: MEDIUM** ‚≠ê

### **Step 9.3: Monitoring (Day 27)**
**Priority: MEDIUM** ‚≠ê

### **Step 9.4: Docker Deployment (Day 28)**
**Priority: HIGH** ‚≠ê‚≠ê

---

## üß™ **Testing Strategy**

### **Test Each Phase**
```python
# Example test for Phase 3
async def test_basic_middleware():
    middleware = AgenticMiddleware()
    await middleware.initialize()
    
    context = ExecutionContext(
        session_id="test",
        user_id="test",
        project_id="test",
        workspace_path="/tmp"
    )
    
    response = await middleware.process_request(
        "Create a Python function",
        context
    )
    
    assert response["status"] == "completed"
```

## üìä **Success Metrics by Phase**

| Phase | Success Criteria | Time |
|-------|-----------------|------|
| Phase 1 | FastAPI server running, basic models defined | 2 days |
| Phase 2 | Simple agent can execute and return results | 2 days |
| Phase 3 | Middleware routes requests to correct agents | 3 days |
| Phase 4 | REST API accepts and processes chat messages | 2 days |
| Phase 5 | Multiple agents handling different intents | 5 days |
| Phase 6 | Memory and planning working with real LLMs | 4 days |
| Phase 7 | Real-time WebSocket communication | 3 days |
| Phase 8 | Frontend can chat with backend | 4 days |
| Phase 9 | Production-ready with security and monitoring | 4 days |

## üéØ **Key Implementation Tips**

### **Start Simple, Build Up**
- Begin with hardcoded responses before LLM integration
- Use mock clients for external dependencies
- Test each component in isolation

### **Validate Early and Often**
- Write tests for each phase
- Test with real user scenarios
- Get feedback on UX before building complex features

### **Focus on Core Value First**
- Phase 1-4 gives you a working chat interface
- Phase 5-6 adds real AI capabilities
- Phase 7-9 makes it production-ready

### **Risk Mitigation**
- Keep LLM integration simple initially
- Have fallback responses for agent failures
- Plan for rate limiting from the start

This roadmap gets you from **zero to working AI code editor** in about 8 weeks, with a functional prototype after just 2-3 weeks! üöÄ